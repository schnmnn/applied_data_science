{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "650e2b959116c766bc5782adc8da0a74",
     "grade": false,
     "grade_id": "cell-12add5077b6e89c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 0.1** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the Jupyter Notebook FAQ course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "In this assignment you'll explore the relationship between model complexity and generalization performance, by adjusting key parameters of various supervised learning models. Part 1 of this assignment will look at regression and Part 2 will look at classification.\n",
    "\n",
    "## Part 1 - Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0eb030de7472f474f2acbff31502ea12",
     "grade": false,
     "grade_id": "cell-82820d5bbf6c4ddf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "n = 15\n",
    "x = np.linspace(0,10,n) + np.random.randn(n)/5\n",
    "y = np.sin(x)+x/6 + np.random.randn(n)/10\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=0)\n",
    "\n",
    "def intro():\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(X_train, y_train, label='training data')\n",
    "    plt.scatter(X_test, y_test, label='test data')\n",
    "    plt.legend(loc=4);\n",
    "\n",
    "intro()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f1010623ab32922f56be3c510bda9b4",
     "grade": false,
     "grade_id": "cell-035dbae9bf827659",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Write a function that fits a polynomial LinearRegression model on the *training data* `X_train` for degrees 1, 3, 6, and 9. (Use PolynomialFeatures in sklearn.preprocessing to create the polynomial features and then fit a linear regression model) For each model, find 100 predicted values over the interval x = 0 to 10 (e.g. `np.linspace(0,10,100)`) and store this in a numpy array. The first row of this array should correspond to the output from the model trained on degree 1, the second row degree 3, the third row degree 6, and the fourth row degree 9.\n",
    "\n",
    "<img src=\"assets/polynomialreg1.png\" style=\"width: 1000px;\"/>\n",
    "\n",
    "The figure above shows the fitted models plotted on top of the original data (using `plot_one()`).\n",
    "\n",
    "<br>\n",
    "*This function should return a numpy array with shape `(4, 100)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8436104c34e3504afe30bc2525bb75ea",
     "grade": false,
     "grade_id": "cell-6c513a17d17152d5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def answer_one():\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    \n",
    "    #List to store predictions\n",
    "    degree_predictions = []\n",
    "    \n",
    "    # Data that should be predicted\n",
    "    X = np.linspace(0,10,100).reshape(-1,1)\n",
    "    \n",
    "    for degree in [1,3,6,9]:\n",
    "        poly = PolynomialFeatures(degree)\n",
    "\n",
    "        X_train_poly = poly.fit_transform(X_train.reshape(-1,1))\n",
    "        linreg = LinearRegression().fit(X_train_poly,y_train)\n",
    "\n",
    "        X_poly = poly.fit_transform(X.reshape(-1,1)) \n",
    "        predict = linreg.predict(X_poly)\n",
    "        degree_predictions.append(predict)\n",
    "    \n",
    "    return degree_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "490e096030c2a5920f27296066dbbf96",
     "grade": true,
     "grade_id": "cell-4b3a4b2c2971710c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# feel free to use the function plot_one() to replicate the figure \n",
    "# from the prompt once you have completed question one\n",
    "\n",
    "def plot_one(degree_predictions):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(X_train, y_train, 'o', label='training data', markersize=10)\n",
    "    plt.plot(X_test, y_test, 'o', label='test data', markersize=10)\n",
    "    for i,degree in enumerate([1,3,6,9]):\n",
    "        plt.plot(np.linspace(0,10,100), degree_predictions[i], alpha=0.8, lw=2, label='degree={}'.format(degree))\n",
    "    plt.ylim(-1,2.5)\n",
    "    plt.legend(loc=4)\n",
    "\n",
    "plot_one(answer_one())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce5717d687d83501f4a40391d1343a6c",
     "grade": false,
     "grade_id": "cell-0dc74766a78dd360",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Write a function that fits a polynomial LinearRegression model on the training data `X_train` for degrees 0 through 9. For each model compute the $R^2$ (coefficient of determination) regression score on the training data as well as the the test data, and return both of these arrays in a tuple.\n",
    "\n",
    "*This function should return a tuple of numpy arrays `(r2_train, r2_test)`. Both arrays should have shape `(10,)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "396058b742b2cec36e4553b8f24ed21c",
     "grade": false,
     "grade_id": "cell-ae3a83e5eef54645",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def answer_two():\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    r2_train = np.array([])\n",
    "    r2_test = np.array([])\n",
    "\n",
    "    for degree in range(10):\n",
    "        poly = PolynomialFeatures(degree)\n",
    "\n",
    "        X_train_poly = poly.fit_transform(X_train.reshape(-1,1))\n",
    "        X_test_poly =  poly.fit_transform(X_test.reshape(-1,1))\n",
    "        \n",
    "        linreg = LinearRegression().fit(X_train_poly,y_train)\n",
    "        r2_train = np.append(r2_train,linreg.score(X_train_poly,y_train))\n",
    "        r2_test = np.append(r2_test,linreg.score(X_test_poly,y_test))\n",
    "    return (r2_train, r2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.42924578, 0.4510998 , 0.58719954, 0.91941945,\n",
       "        0.97578641, 0.99018233, 0.99352509, 0.99637545, 0.99803706]),\n",
       " array([-0.47808642, -0.45237104, -0.06856984,  0.00533105,  0.73004943,\n",
       "         0.87708301,  0.9214094 ,  0.92021504,  0.63247948, -0.64525365]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46df6eab1f30c0fb905cecd91de7f86a",
     "grade": false,
     "grade_id": "cell-a61e61b55b9465fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Based on the $R^2$ scores from question 2 (degree levels 0 through 9), what degree level corresponds to a model that is underfitting? What degree level corresponds to a model that is overfitting? What choice of degree level would provide a model with good generalization performance on this dataset? \n",
    "\n",
    "(Hint: Try plotting the $R^2$ scores from question 2 to visualize the relationship)\n",
    "\n",
    "*This function should return a tuple with the degree values in this order: `(Underfitting, Overfitting, Good_Generalization)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd6238e841d4d51362c3687f8ae4841c",
     "grade": false,
     "grade_id": "cell-721bb32d2df3020f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def answer_three():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffd5b85a04844aeed8bcfe38dd943faf",
     "grade": true,
     "grade_id": "cell-877e9f32963e0d5a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "828cf6c6860722b3f89ca2a667a8dd4f",
     "grade": false,
     "grade_id": "cell-a99d81381fbc35ee",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Training models on high degree polynomial features can result in overfitting. Train two models: a non-regularized LinearRegression model and a Lasso Regression model (with parameters `alpha=0.01`, `max_iter=10000`, `tol=0.1`) on polynomial features of degree 12. Return the $R^2$ score for LinearRegression and Lasso model's test sets.\n",
    "\n",
    "*This function should return a tuple `(LinearRegression_R2_test_score, Lasso_R2_test_score)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fc87206e6c599bd5e911bfbf6d833dc4",
     "grade": false,
     "grade_id": "cell-55ab7af2f78e174e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def answer_four():\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.linear_model import Lasso, LinearRegression\n",
    "    from sklearn.metrics import r2_score\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b7288eaac59a3be8999b26c2bdef060",
     "grade": true,
     "grade_id": "cell-f1ccfec3713e840c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "17c987a4ffba18ec6723810fba58241f",
     "grade": false,
     "grade_id": "cell-31c2ed693fab43e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Part 2 - Classification\n",
    "\n",
    "For this section of the assignment we will be working with the [UCI Mushroom Data Set](http://archive.ics.uci.edu/ml/datasets/Mushroom?ref=datanews.io) stored in `mushrooms.csv`. The data will be used to trian a model to predict whether or not a mushroom is poisonous. The following attributes are provided:\n",
    "\n",
    "*Attribute Information:*\n",
    "\n",
    "1. cap-shape: bell=b, conical=c, convex=x, flat=f, knobbed=k, sunken=s \n",
    "2. cap-surface: fibrous=f, grooves=g, scaly=y, smooth=s \n",
    "3. cap-color: brown=n, buff=b, cinnamon=c, gray=g, green=r, pink=p, purple=u, red=e, white=w, yellow=y \n",
    "4. bruises?: bruises=t, no=f \n",
    "5. odor: almond=a, anise=l, creosote=c, fishy=y, foul=f, musty=m, none=n, pungent=p, spicy=s \n",
    "6. gill-attachment: attached=a, descending=d, free=f, notched=n \n",
    "7. gill-spacing: close=c, crowded=w, distant=d \n",
    "8. gill-size: broad=b, narrow=n \n",
    "9. gill-color: black=k, brown=n, buff=b, chocolate=h, gray=g, green=r, orange=o, pink=p, purple=u, red=e, white=w, yellow=y \n",
    "10. stalk-shape: enlarging=e, tapering=t \n",
    "11. stalk-root: bulbous=b, club=c, cup=u, equal=e, rhizomorphs=z, rooted=r, missing=? \n",
    "12. stalk-surface-above-ring: fibrous=f, scaly=y, silky=k, smooth=s \n",
    "13. stalk-surface-below-ring: fibrous=f, scaly=y, silky=k, smooth=s \n",
    "14. stalk-color-above-ring: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y \n",
    "15. stalk-color-below-ring: brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y \n",
    "16. veil-type: partial=p, universal=u \n",
    "17. veil-color: brown=n, orange=o, white=w, yellow=y \n",
    "18. ring-number: none=n, one=o, two=t \n",
    "19. ring-type: cobwebby=c, evanescent=e, flaring=f, large=l, none=n, pendant=p, sheathing=s, zone=z \n",
    "20. spore-print-color: black=k, brown=n, buff=b, chocolate=h, green=r, orange=o, purple=u, white=w, yellow=y \n",
    "21. population: abundant=a, clustered=c, numerous=n, scattered=s, several=v, solitary=y \n",
    "22. habitat: grasses=g, leaves=l, meadows=m, paths=p, urban=u, waste=w, woods=d\n",
    "\n",
    "<br>\n",
    "\n",
    "The data in the mushrooms dataset is currently encoded with strings. These values will need to be encoded to numeric to work with sklearn. We'll use pd.get_dummies to convert the categorical variables into indicator variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af003949c9018bed0b7c646cd4b0b03f",
     "grade": false,
     "grade_id": "cell-e7c80d01d6d17d4d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "mush_df = pd.read_csv('assets/mushrooms.csv')\n",
    "mush_df2 = pd.get_dummies(mush_df)\n",
    "\n",
    "X_mush = mush_df2.iloc[:,2:]\n",
    "y_mush = mush_df2.iloc[:,1]\n",
    "\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_mush, y_mush, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a309b42233d5f15c15d791c51599a8df",
     "grade": false,
     "grade_id": "cell-586eff0179eb4e48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Using `X_train` and `y_train` from the preceeding cell, train a DecisionTreeClassifier with default parameters and random_state=0. What are the 5 most important features found by the decision tree?\n",
    "\n",
    "*This function should return a list of length 5 of the feature names in descending order of importance.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b34331dd3525c3b25fbc73519bbd7e01",
     "grade": false,
     "grade_id": "cell-55ff1f0e1941bc35",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def answer_five():\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4102243cb57cca9cf6c64b8377eef091",
     "grade": true,
     "grade_id": "cell-45bb9fef0723e714",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dac6022b713452cb6bb37c201782b44d",
     "grade": false,
     "grade_id": "cell-175384240dac6faa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 6\n",
    "\n",
    "For this question, use the `validation_curve` function in `sklearn.model_selection` to determine training and test scores for a Support Vector Classifier (`SVC`) with varying parameter values.\n",
    "\n",
    "Create an `SVC` with default parameters (i.e. `kernel='rbf', C=1`) and `random_state=0`. Recall that the kernel width of the RBF kernel is controlled using the `gamma` parameter.  Explore the effect of `gamma` on classifier accuracy by using the `validation_curve` function to find the training and test scores for 6 values of `gamma` from `0.0001` to `10` (i.e. `np.logspace(-4,1,6)`).\n",
    "\n",
    "For each level of `gamma`, `validation_curve` will use 3-fold cross validation (use `cv=3, n_jobs=2` as parameters for `validation_curve`), returning two 6x3 (6 levels of gamma x 3 fits per level) arrays of the scores for the training and test sets in each fold.\n",
    "\n",
    "Find the mean score across the five models for each level of `gamma` for both arrays, creating two arrays of length 6, and return a tuple with the two arrays.\n",
    "\n",
    "e.g.\n",
    "\n",
    "if one of your array of scores is\n",
    "\n",
    "    array([[ 0.5,  0.4,  0.6],\n",
    "           [ 0.7,  0.8,  0.7],\n",
    "           [ 0.9,  0.8,  0.8],\n",
    "           [ 0.8,  0.7,  0.8],\n",
    "           [ 0.7,  0.6,  0.6],\n",
    "           [ 0.4,  0.6,  0.5]])\n",
    "       \n",
    "it should then become\n",
    "\n",
    "    array([ 0.5,  0.73333333,  0.83333333,  0.76666667,  0.63333333, 0.5])\n",
    "\n",
    "*This function should return a tuple of numpy arrays `(training_scores, test_scores)` where each array in the tuple has shape `(6,)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65d5ad93c05a09042f9a32c0f8b84b9f",
     "grade": false,
     "grade_id": "cell-87cac6bdc8ea12a4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def answer_six():\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.model_selection import validation_curve\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78bed9b2bb9eabdf0c3072db27c1af28",
     "grade": true,
     "grade_id": "cell-ae2a630e8862c3a3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6ac0808fe91645d2f5a9b37bdce3dda",
     "grade": false,
     "grade_id": "cell-40596e2acf966014",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 7\n",
    "\n",
    "Based on the scores from question 6, what gamma value corresponds to a model that is underfitting? What gamma value corresponds to a model that is overfitting? What choice of gamma would provide a model with good generalization performance on this dataset? \n",
    "\n",
    "(Hint: Try plotting the scores from question 6 to visualize the relationship)\n",
    "\n",
    "*This function should return a tuple with the degree values in this order: `(Underfitting, Overfitting, Good_Generalization)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ac5a576f40d02669a67b9a16cac123a2",
     "grade": false,
     "grade_id": "cell-f159223bb2d29699",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def answer_seven():\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ece7c13194d0f29a3dd840ff2a87ea4",
     "grade": true,
     "grade_id": "cell-6372c6701a14c068",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
